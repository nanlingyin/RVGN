import openai
import os
from typing import Optional, Dict, Any

class LLMAPIClient:
    """
    A client to interact with Large Language Models (LLMs) like OpenAI's GPT series.
    It handles API key management, request formation, and response parsing.
    """
    def __init__(self, api_key: Optional[str] = None, base_url: Optional[str] = None, model: str = "gpt-4o-mini"):
        """
        Initializes the LLM API client.

        Args:
            api_key: The OpenAI API key. If None, attempts to read from OPENAI_API_KEY environment variable.
            base_url: The base URL for the OpenAI API. Useful for proxies or custom deployments. 
                      If None, attempts to read from OPENAI_API_BASE environment variable or uses OpenAI's default.
            model: The default model to use for generations (e.g., "gpt-4o-mini", "gpt-4").
        
        Raises:
            ValueError: If the API key is not provided either as an argument or an environment variable.
        """
        self.api_key = api_key or os.getenv("OPENAI_API_KEY")
        self.base_url = base_url or os.getenv("OPENAI_API_BASE") # openai library handles default if this is None
        self.model = model
        
        if not self.api_key:
            raise ValueError("OpenAI API key is required. Set it via the 'api_key' argument or the OPENAI_API_KEY environment variable.")
            
        # Ensure openai library is available
        try:
            import openai
        except ImportError:
            raise ImportError("The 'openai' library is not installed. Please install it using 'pip install openai'")

        self.client = openai.OpenAI(api_key=self.api_key, base_url=self.base_url if self.base_url else None)

    def generate_reasoning(self, problem_description: str, prompt_template: Optional[str] = None, max_tokens: int = 1500, temperature: float = 0.7) -> str:
        """
        Generates a reasoning chain or solution for a given problem description using the LLM.

        Args:
            problem_description: The problem statement or question.
            prompt_template: An optional f-string template for the prompt. Must include '{problem_description}'.
                             If None, a default prompt is used.
            max_tokens: The maximum number of tokens to generate.
            temperature: The sampling temperature for generation (0.0 to 2.0). Lower is more deterministic.

        Returns:
            The LLM-generated reasoning text, or an error message if generation fails.
        """
        if prompt_template:
            prompt = prompt_template.format(problem_description=problem_description)
        else:
            prompt = f"Please provide a detailed step-by-step reasoning process to solve the following problem. Explain each step clearly.\n\nProblem: {problem_description}\n\nReasoning:"

        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": prompt}],
                max_tokens=max_tokens,
                temperature=temperature
            )
            # Ensure response.choices is not empty and message.content is not None
            if response.choices and response.choices[0].message and response.choices[0].message.content:
                return response.choices[0].message.content.strip()
            else:
                return "Error: LLM response was empty or malformed."
        except Exception as e:
            print(f"Error calling OpenAI API for reasoning generation: {e}")
            return f"Error: Could not generate reasoning due to API issue: {e}"

    def critique_and_improve_reasoning(self, original_reasoning: str, problem_description: str, detected_errors: Dict[str, Any], max_tokens: int = 2000, temperature: float = 0.5) -> str:
        """
        Asks the LLM to critique and improve a given reasoning process based on detected errors.

        Args:
            original_reasoning: The initial reasoning text generated by an LLM or provided by a user.
            problem_description: The original problem statement for context.
            detected_errors: A dictionary containing errors and low-confidence points identified by RVGN's GraphErrorDetector.
            max_tokens: Maximum tokens for the improved reasoning.
            temperature: Sampling temperature for the critique and improvement.

        Returns:
            The LLM-generated improved reasoning text, or an error message.
        """
        error_summary_parts = []
        if detected_errors.get("errors"):
            error_summary_parts.append("Detected structural errors in the reasoning graph:")
            for err in detected_errors["errors"]:
                error_summary_parts.append(f"  - Type: {err['type']}, Location: {err.get('location', 'N/A')}, Description: {err['description']}")
        
        if detected_errors.get("low_confidence"):
            error_summary_parts.append("Detected steps with low confidence:")
            for node_id, confidence_score, reason_for_low_confidence in detected_errors["low_confidence"]:
                error_summary_parts.append(f"  - Step/Node ID: {node_id} (Confidence: {confidence_score:.2f}), Reason: {reason_for_low_confidence}")

        if not error_summary_parts:
            return "RVGN found no specific errors to critique. The original reasoning might be structurally sound or errors were not detectable by current rules."

        error_feedback_string = "\n".join(error_summary_parts)

        prompt = (
            f"The following reasoning process was generated to solve a problem. An analysis using a Reasoning Graph Verification Network (RVGN) has identified potential issues.\n\n"
            f"Original Problem:\n'''\n{problem_description}\n'''\n
"
            f"Original Reasoning Process:\n'''\n{original_reasoning}\n'''\n
"
            f"RVGN Analysis Feedback:\n'''\n{error_feedback_string}\n'''\n
"
            f"Your task is to act as an expert logician. Please carefully review the original reasoning, the problem, and the RVGN feedback. "
            f"Then, provide a revised and improved version of the reasoning process that addresses the identified issues. "
            f"The revised reasoning should be clear, logically sound, complete, and directly solve the original problem. "
            f"Explain your improvements if necessary."
        )
        
        try:
            response = self.client.chat.completions.create(
                model=self.model, # Consider using a more capable model for critique if available
                messages=[{"role": "user", "content": prompt}],
                max_tokens=max_tokens,
                temperature=temperature
            )
            if response.choices and response.choices[0].message and response.choices[0].message.content:
                return response.choices[0].message.content.strip()
            else:
                return "Error: LLM response for critique was empty or malformed."
        except Exception as e:
            print(f"Error calling OpenAI API for critique and improvement: {e}")
            return f"Error: Could not generate improved reasoning due to API issue: {e}"

# Example Usage (can be run directly if OPENAI_API_KEY is set)
if __name__ == '__main__':
    # This example requires the OPENAI_API_KEY environment variable to be set.
    # You can also pass api_key and base_url directly to the constructor.
    print("Attempting to initialize LLMAPIClient...")
    try:
        # Ensure you have set your OPENAI_API_KEY environment variable
        # or pass it directly: client = LLMAPIClient(api_key="YOUR_API_KEY", model="gpt-4o-mini")
        client = LLMAPIClient(model="gpt-4o-mini") 
        print("LLMAPIClient initialized successfully.")
        
        problem = "If all bloops are razzies and all razzies are lazzies, are all bloops lazzies? Explain why."
        print(f"\nGenerating reasoning for problem: '{problem}'")
        reasoning = client.generate_reasoning(problem)
        print(f"\nGenerated Reasoning:\n{'-'*30}\n{reasoning}\n{'-'*30}")

        # Simulate some errors for critique
        simulated_errors = {
            "errors": [{"type": "reasoning_gap", "location": "Step 1 and Step 2", "description": "Missing explicit link"}],
            "low_confidence": [("step_2_node", 0.5, "Conclusion seems weak")]
        }
        print(f"\nRequesting critique and improvement based on simulated errors...")
        improved_reasoning = client.critique_and_improve_reasoning(reasoning, problem, simulated_errors)
        print(f"\nImproved Reasoning:\n{'-'*30}\n{improved_reasoning}\n{'-'*30}")

    except ImportError as ie:
        print(f"Import Error: {ie}")
    except ValueError as ve:
        print(f"Configuration Error: {ve}")
    except Exception as e:
        print(f"An unexpected error occurred during example usage: {e}")
